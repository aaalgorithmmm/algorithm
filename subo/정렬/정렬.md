# 정렬 알고리즘 정리 (버블/선택/삽입/퀵/병합/기수)

아래 설명은 제공한 코드 구현 방식( `int[]` 기준 )과 동일한 관점에서 정리했습니다.

---

## 04-1 버블 정렬 (Bubble Sort)

### 개념
인접한 두 원소를 비교해서 **큰 값을 오른쪽으로 계속 밀어내는** 정렬입니다.  
한 번의 “패스(pass)”가 끝나면 가장 큰 값이 맨 뒤에 확정됩니다.

### 동작 방식(코드 기준)
- 바깥 루프 `pass`는 정렬 패스 횟수
- 안쪽 루프는 `length - 1 - pass`까지만 비교 (뒤쪽은 이미 확정이라 제외)
- swap이 한 번도 일어나지 않으면 이미 정렬된 상태 → **조기 종료(swapped)**

### 시간/공간/특징
- 평균/최악: `O(n^2)`
- 최선(거의 정렬 + 조기 종료): `O(n)`
- 추가 메모리: `O(1)`
- 안정 정렬(Stable): **가능**(인접 swap만 수행하므로 같은 값 순서 유지)

### 언제 쓰나?
- 실무에선 거의 안 씀(교육/개념 확인용)
- “조기 종료” 개념 보여주기에는 좋음

---

## 04-2 선택 정렬 (Selection Sort)

### 개념
매 단계에서 **가장 작은 값(min)을 찾아 현재 위치로 가져오는** 정렬입니다.  
즉, i번째 자리에 들어갈 값을 “선택”합니다.

### 동작 방식(코드 기준)
- `currentIndex` 위치에 올 최소값 인덱스 `minIndex`를 찾음
- 찾은 후 `currentIndex <-> minIndex` swap
- 이 과정을 끝까지 반복

### 시간/공간/특징
- 평균/최악/최선: `O(n^2)` (항상 최소를 찾느라 비교를 많이 함)
- 추가 메모리: `O(1)`
- 안정 정렬(Stable): **아님**
  - swap 때문에 같은 값의 상대 순서가 깨질 수 있음
- swap 횟수는 최대 `n-1`로 적은 편

### 언제 쓰나?
- 비교 횟수는 많지만 swap이 적어서 “쓰기 비용이 큰 상황”에서 언급되곤 함
- 실무에선 역시 거의 안 씀(개념/교육용)

---

## 04-3 삽입 정렬 (Insertion Sort)

### 개념
카드 정렬처럼, 왼쪽 구간을 **항상 정렬된 상태로 유지**하면서  
새 원소를 알맞은 위치에 **끼워 넣는(insertion)** 방식입니다.

### 동작 방식(코드 기준)
- `currentIndex=1`부터 시작해 `key=a[currentIndex]`를 잡음
- 왼쪽(정렬된 구간)에서 `key`보다 큰 값들을 오른쪽으로 밀어 공간 확보
- 확보된 위치에 `key`를 삽입

### 시간/공간/특징
- 평균/최악: `O(n^2)`
- 최선(이미 정렬/거의 정렬): `O(n)`에 가까움
- 추가 메모리: `O(1)`
- 안정 정렬(Stable): **맞음**
  - `a[insertPosition] > key` 조건이라 같은 값은 밀지 않음

### 언제 쓰나?
- **거의 정렬된 데이터**에서 매우 강력
- 작은 배열에서 오버헤드가 적어 실무에서도 부분적으로 쓰임(하이브리드 정렬 내부 등)

---

## 04-4 퀵 정렬 (Quick Sort)

### 개념
피벗(pivot)을 기준으로 원소들을 **왼쪽(작은 값) / 오른쪽(큰 값)** 으로 분할(partition)한 뒤  
각 구간을 재귀적으로 정렬하는 **분할정복** 알고리즘입니다.

### 동작 방식(코드 기준)
- pivot: `a[(left + right) >>> 1]` (가운데 값)
- `leftPtr`는 왼쪽에서 pivot 이상을 찾고, `rightPtr`는 오른쪽에서 pivot 이하를 찾음
- 두 포인터가 교차하기 전까지 swap하며 partition 수행
- 이후 `(left ~ rightPtr)`, `(leftPtr ~ right)` 두 구간을 재귀 호출

### 시간/공간/특징
- 평균: `O(n log n)`
- 최악: `O(n^2)` (피벗 선택이 계속 나쁘면)
- 추가 메모리: `O(log n)` (재귀 호출 스택)
- 안정 정렬(Stable): **아님** (swap으로 같은 값 순서가 깨질 수 있음)

### 언제 쓰나?
- 평균 성능이 매우 좋아 대표적인 고성능 정렬로 자주 설명됨
- 다만 최악 케이스 방지(랜덤 피벗/3-way partition/하이브리드)가 실무 포인트

---

## 04-5 병합 정렬 (Merge Sort)

### 개념
배열을 반으로 나누어 각각 정렬한 뒤,  
**정렬된 두 배열을 병합(merge)** 해서 전체를 정렬하는 **분할정복** 알고리즘입니다.

### 동작 방식(코드 기준)
- `mergeSort(a, tmp, left, right)`로 재귀 분할
- `merge()`에서 두 포인터(`leftIdx`, `rightIdx`)로 작은 값을 tmp에 순서대로 복사
- merge 완료 후 tmp 구간을 원본 배열로 복사

### 시간/공간/특징
- 평균/최악/최선: `O(n log n)` (항상 일정)
- 추가 메모리: `O(n)` (tmp 배열 필요)
- 안정 정렬(Stable): **맞음**
  - merge 시 `a[leftIdx] <= a[rightIdx]`로 동일 값이면 왼쪽을 먼저 선택 → 안정성 유지

### 언제 쓰나?
- 성능이 예측 가능하고 안정 정렬이 필요할 때 적합
- 대신 메모리 사용량이 증가하는 게 단점

---

## 04-6 기수 정렬 (Radix Sort) - 음수 없는 int[]

### 개념
비교 기반 정렬이 아니라, 숫자를 **자릿수(1의 자리 → 10의 자리 → 100의 자리...)** 기준으로 여러 번 정렬하여  
최종적으로 전체 정렬을 완성하는 방식입니다.  
각 자릿수 정렬은 보통 **계수 정렬(Counting Sort)** 을 안정적으로 수행해야 합니다.

### 동작 방식(코드 기준, LSD 방식)
- `exponent=1,10,100...` 순서로 자릿수 증가
- 현재 자릿수 digit = `(value / exponent) % 10`
- `count[10]`으로 빈도 계산 → prefix sum으로 누적 위치 계산
- **뒤에서부터 output에 채움**으로 안정성 확보
- output을 원본으로 복사 후 다음 자릿수 진행

### 시간/공간/특징
- 시간: `O(d * (n + k))`
  - d: 자릿수 개수, k: 진법(10)
- 추가 메모리: `O(n + k)` (output + count)
- 안정 정렬(Stable): **맞음** (뒤에서 채우는 stable counting sort 구조)
- 제약: 현재 구현은 **음수 없음** 전제

### 언제 쓰나?
- 정수/문자열 등 “자릿수”가 있고 범위/형태가 맞으면 매우 빠름
- 음수 지원은 별도 처리(양수/음수 분리 후 합치기 등) 필요

---
